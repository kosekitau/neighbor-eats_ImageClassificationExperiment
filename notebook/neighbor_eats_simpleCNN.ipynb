{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neighbor-eats_simpleCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pPDlPzQZUibe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import  torch \n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_dataset = h5py.File(\"/content/drive/MyDrive/projects/neighbor/data/datasets.hdf5\", \"r\")\n",
        "\n",
        "X_train = np.array(all_dataset[\"train_set_X\"])\n",
        "y_train = np.array(all_dataset[\"train_set_y\"])\n",
        "\n",
        "X_val = np.array(all_dataset[\"val_set_X\"])\n",
        "y_val = np.array(all_dataset[\"val_set_y\"])\n",
        "\n",
        "X_test = np.array(all_dataset[\"eval_set_X\"])\n",
        "y_test = np.array(all_dataset[\"eval_set_y\"])"
      ],
      "metadata": {
        "id": "M2VQbPqHh6NW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39G1zSVQtjgt",
        "outputId": "af9e0f95-c2da-48cf-dfc1-ea04209c629e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000, 64, 64, 3) (1000, 64, 64, 3) (1000, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 255値で正規化\n",
        "X_train_norm = X_train / 255.0\n",
        "X_val_norm = X_val / 255.0\n",
        "X_test_norm = X_test / 255.0"
      ],
      "metadata": {
        "id": "cz16fkVeirHZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.x = torch.Tensor(x).permute(0,3,1,2).float() #NCHW -> NHWC\n",
        "        self.y = torch.Tensor(y).type(torch.LongTensor)\n",
        "               \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.x[index] / 255.0\n",
        "        target = self.y[index]\n",
        "        \n",
        "        return image, target"
      ],
      "metadata": {
        "id": "V8Gswl5YlYSO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(ImageDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
        "val_dataloader = DataLoader(ImageDataset(X_val, y_val), batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
        "test_dataloader = DataLoader(ImageDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
        "\n",
        "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}"
      ],
      "metadata": {
        "id": "WLHgfXChCLq0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力画像は(64, 64)の3チャンネル\n",
        "model = nn.Sequential(\n",
        "    nn.ZeroPad2d(padding=3),\n",
        "    #入力チャンネル数, 出力チャンネル数,(フィルタの数) フィルタ(カーネル)の長さ\n",
        "    nn.Conv2d(3, 64, 11, stride=1), # フィルタ64枚で、カーネルサイズは11にしたい\n",
        "    nn.BatchNorm2d(64), # 入力チャンネル数\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "    nn.Conv2d(64, 64, 2, stride=1),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "    nn.Conv2d(64, 64, 2, stride=1),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(2304, 2)\n",
        ")"
      ],
      "metadata": {
        "id": "vclfe7NiCkOp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 10\n",
        "lr = 2e-4\n",
        "\n",
        "opt = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "mkTcbamNHqU8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    \n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print(device)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0 # epochの損失和\n",
        "            running_corrects = 0 # epochの正解数\n",
        "\n",
        "            for inputs, labels in dataloaders_dict[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                #学習フェーズならパラメータ更新\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "sY7hF2yZMno3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, criterion, opt, n_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMgd7dioMt43",
        "outputId": "4402fc5a-6b7d-4dbe-b7ab-ecaa73251908"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.4319 Acc: 0.7893\n",
            "val Loss: 0.4988 Acc: 0.7530\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.3021 Acc: 0.8607\n",
            "val Loss: 0.4825 Acc: 0.7870\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.2396 Acc: 0.8940\n",
            "val Loss: 0.2955 Acc: 0.8750\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.2182 Acc: 0.9033\n",
            "val Loss: 0.3056 Acc: 0.8680\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1697 Acc: 0.9317\n",
            "val Loss: 0.3524 Acc: 0.8330\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1448 Acc: 0.9417\n",
            "val Loss: 0.4914 Acc: 0.8200\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1271 Acc: 0.9523\n",
            "val Loss: 0.3084 Acc: 0.8810\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1101 Acc: 0.9547\n",
            "val Loss: 0.3826 Acc: 0.8440\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0852 Acc: 0.9687\n",
            "val Loss: 0.4491 Acc: 0.8400\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0701 Acc: 0.9770\n",
            "val Loss: 0.3156 Acc: 0.8720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "epoch_corrects = 0\n",
        "predictions = []\n",
        "targets = []\n",
        "for inputs, labels in (test_dataloader):\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  with torch.set_grad_enabled(False):\n",
        "     outputs = model(inputs)\n",
        "     _, preds = torch.max(outputs, 1)\n",
        "     predictions.extend(preds.to('cpu').detach().numpy().copy())\n",
        "     targets.extend(labels.to('cpu').detach().numpy().copy())\n",
        "     epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
        "print('Acc: {:.4f}'.format(epoch_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sagy87P66v1k",
        "outputId": "f52f6ee2-3980-4ddb-e1d9-491754d1aad2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Acc: 0.8490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confmat = confusion_matrix(y_true=targets, y_pred=predictions)\n",
        "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "\n",
        "for i in range(confmat.shape[0]):\n",
        "  for j in range(confmat.shape[1]):\n",
        "    ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "precision = precision_score(targets, predictions)\n",
        "recall = recall_score(targets, predictions)\n",
        "print(f'Precision：{precision}.')\n",
        "print(f'Recall：{recall}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "vi3Uwyx7A-6M",
        "outputId": "fd84c802-4c34-4c3f-ebe8-232858296f7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 180x180 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision：0.7976391231028668.\n",
            "Recall：0.9536290322580645.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_dataset = h5py.File(\"/content/drive/MyDrive/projects/neighbor/data/ex_testdatasets.hdf5\", \"r\")\n",
        "\n",
        "X_extest = np.array(all_dataset[\"train_set_X\"])\n",
        "y_extest = np.array(all_dataset[\"train_set_y\"])\n",
        "\n",
        "BS = 15\n",
        "\n",
        "extest_dataloader = DataLoader(ImageDataset(X_train, y_train), batch_size=BS, shuffle=True, drop_last = True)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "epoch_corrects = 0\n",
        "predictions = []\n",
        "targets = []\n",
        "for inputs, labels in (extest_dataloader):\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  with torch.set_grad_enabled(False):\n",
        "     outputs = model(inputs)\n",
        "     _, preds = torch.max(outputs, 1)\n",
        "     predictions.extend(preds.to('cpu').detach().numpy().copy())\n",
        "     targets.extend(labels.to('cpu').detach().numpy().copy())\n",
        "     epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "epoch_acc = epoch_corrects.double() / len(extest_dataloader.dataset)\n",
        "print('Acc: {:.4f}'.format(epoch_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6VFmhPACXU-",
        "outputId": "72333f22-4fb1-4b40-abd4-6d421c893b4e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Acc: 0.7333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = confusion_matrix(y_true=targets, y_pred=predictions)\n",
        "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "\n",
        "for i in range(confmat.shape[0]):\n",
        "  for j in range(confmat.shape[1]):\n",
        "    ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "precision = precision_score(targets, predictions)\n",
        "recall = recall_score(targets, predictions)\n",
        "print(f'Precision：{precision}.')\n",
        "print(f'Recall：{recall}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TrnKbg4dKstR",
        "outputId": "7ae7af74-bdd4-4bed-cb17-db52fe824028"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 180x180 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision：0.625.\n",
            "Recall：0.8333333333333334.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pY-IhqnvMYLm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}